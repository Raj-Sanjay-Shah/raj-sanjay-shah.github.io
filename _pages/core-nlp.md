---
title: "Core NLP & Model Operations"
permalink: /core-nlp/
layout: page
description: "Unlearning, text watermarking, continual learning, and domain adaptation work."
---

## Core NLP & Model Ops

This theme bundles the infrastructure that keeps language models reliable once they leave the lab: unlearning, watermarking, continual learning, and domain adaptation for high-stakes verticals.

### Featured Work

- **Beyond the Unlearning Mirage** - Dynamic evaluations that stress-test multi-hop leakage and fuse in watermarking + continual-learning tactics.
- **Domain-Specific Evaluations With Real Consequences** - Finance, medical, and cybersecurity benchmarks that measure impact instead of just BLEU.

### Highlights

1. **Unlearning & Safety**
   - Dynamic probe generation (single hop â†’ multi-hop, alias chains)
   - Activation-pathway tracing to confirm concepts are truly removed
   - Pip package + leaderboard for reproducible stress tests

2. **Provenance & Watermarking**
   - Taxonomy covering robustness under editing/fine-tuning
   - Guidance for platform operators to audit leaked generations

3. **Continual Learning & Domain Adaptation**
   - Power-law learning environments that mitigate catastrophic interference
   - Domain-specific adapters for finance, clinical narratives, and more

### How to use this work

- Plug your unlearning method into the evaluator before deployment.
- Cite the watermarking taxonomy when rolling out provenance policies.
- Adopt the domain benchmarks when showcasing vertical LLM claims.

Questions or collab ideas? Drop a note in Discord or email-this stack is meant to be extended.
